{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249173f5-697e-4952-80b0-3afac10870d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allisonkrinsky/Desktop/posit/connect-cloud-deploy/cc/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import packages to use during training\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37479bc5-ffc8-41f9-9dcb-a60750c875be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>fold</th>\n",
       "      <th>label</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_id</th>\n",
       "      <th>url</th>\n",
       "      <th>preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/test/neg/1821_4.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>neg</td>\n",
       "      <td>4</td>\n",
       "      <td>1821</td>\n",
       "      <td>http://www.imdb.com/title/tt0138541/usercomments</td>\n",
       "      <td>Alan Rickman &amp; Emma Thompson give good perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/test/neg/9487_1.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "      <td>9487</td>\n",
       "      <td>http://www.imdb.com/title/tt0202521/usercomments</td>\n",
       "      <td>I have seen this movie and I did not care for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/test/neg/4604_4.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>neg</td>\n",
       "      <td>4</td>\n",
       "      <td>4604</td>\n",
       "      <td>http://www.imdb.com/title/tt0417658/usercomments</td>\n",
       "      <td>In Los Angeles  the alcoholic and lazy Hank Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/test/neg/2828_2.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>neg</td>\n",
       "      <td>2</td>\n",
       "      <td>2828</td>\n",
       "      <td>http://www.imdb.com/title/tt0066105/usercomments</td>\n",
       "      <td>This film is bundled along with \"Gli fumavano ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/test/neg/10890_1.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "      <td>10890</td>\n",
       "      <td>http://www.imdb.com/title/tt0787505/usercomments</td>\n",
       "      <td>I only comment on really very good films and o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path  fold label  rating  review_id  \\\n",
       "0   data/test/neg/1821_4.txt  test   neg       4       1821   \n",
       "1   data/test/neg/9487_1.txt  test   neg       1       9487   \n",
       "2   data/test/neg/4604_4.txt  test   neg       4       4604   \n",
       "3   data/test/neg/2828_2.txt  test   neg       2       2828   \n",
       "4  data/test/neg/10890_1.txt  test   neg       1      10890   \n",
       "\n",
       "                                                url  \\\n",
       "0  http://www.imdb.com/title/tt0138541/usercomments   \n",
       "1  http://www.imdb.com/title/tt0202521/usercomments   \n",
       "2  http://www.imdb.com/title/tt0417658/usercomments   \n",
       "3  http://www.imdb.com/title/tt0066105/usercomments   \n",
       "4  http://www.imdb.com/title/tt0787505/usercomments   \n",
       "\n",
       "                                             preview  \n",
       "0  Alan Rickman & Emma Thompson give good perform...  \n",
       "1  I have seen this movie and I did not care for ...  \n",
       "2  In Los Angeles  the alcoholic and lazy Hank Ch...  \n",
       "3  This film is bundled along with \"Gli fumavano ...  \n",
       "4  I only comment on really very good films and o...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"IMDB-Movie-Reviews/supervised.csv\") \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7638ca8-f131-4995-9596-055fcf1d0153",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df.fold == 'train'][:1000]\n",
    "test = df[df.fold == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e3ddc2-4928-4e6e-96e0-300861f32910",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d44baa-a713-439b-9cb1-b3fda804bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for encoding of the text reviews\n",
    "def convert_example_to_feature(review):\n",
    "  return tokenizer.encode_plus(review,\n",
    "                add_special_tokens = True, # add [CLS], [SEP]\n",
    "                max_length = max_length, # max length of the text that can go to BERT\n",
    "                pad_to_max_length = True, # add [PAD] tokens\n",
    "                return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "299c5fd3-195d-4732-ba61-770f65da6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4508cc5e-dce4-4dec-bc2a-c74302cf99c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to format the model output \n",
    "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
    "  return {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"token_type_ids\": token_type_ids,\n",
    "      \"attention_mask\": attention_masks,\n",
    "  }, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ea40f40-850e-430f-865c-25b78765b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting all the functions together to complete the tokenization process\n",
    "label_map = {'pos': 1, 'neg': 0}\n",
    "\n",
    "def encode_examples(ds, limit=-1):\n",
    "  input_ids_list = []\n",
    "  token_type_ids_list = []\n",
    "  attention_mask_list = []\n",
    "  label_list = []\n",
    "  if (limit > 0):\n",
    "      ds = ds.take(limit)\n",
    "  for path, label in zip(df['path'], df['label']):\n",
    "    review = open(\"IMDB-Movie-Reviews/\"+path, \"r\").read()\n",
    "    bert_input = convert_example_to_feature(review)\n",
    "    input_ids_list.append(bert_input['input_ids'])\n",
    "    token_type_ids_list.append(bert_input['token_type_ids'])\n",
    "    attention_mask_list.append(bert_input['attention_mask'])\n",
    "\n",
    "\n",
    "    numeric_label = label_map[label]  # Convert string label using label_map\n",
    "    label_list.append([numeric_label])\n",
    "    # label_list.append([label])\n",
    "  return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b1cff6-8d52-4683-86ec-e75bb292b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset\n",
    "# ds_train_encoded = encode_examples(train).shuffle(10000).batch(batch_size)\n",
    "# test dataset\n",
    "# ds_test_encoded = encode_examples(test).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da67659a-254c-48f8-94c0-dd4fbe659f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# recommended learning rate for Adam 5e-5, 3e-5, 2e-5\n",
    "learning_rate = 2e-5\n",
    "# we will do just 1 epoch, though multiple epochs might be better as long as we will not overfit the model\n",
    "number_of_epochs = 1\n",
    "# model initialization\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "# choosing Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
    "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de53997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#       ds_train_encoded,\n",
    "#       batch_size=32,\n",
    "#       epochs=number_of_epochs)\n",
    "\n",
    "# model.save(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9f513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e99c54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "# model.load_weights(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e9015f4-796a-42f2-97df-927f96d0c46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"this movie was so good, love the acting and soundtrack\"\n",
    "\n",
    "predict_input = tokenizer.encode(test_sentence,\n",
    "\n",
    "truncation=True,\n",
    "\n",
    "padding=True,\n",
    "\n",
    "return_tensors=\"tf\")\n",
    "\n",
    "tf_output = model.predict(predict_input)[0]\n",
    "tf_prediction = tf.nn.softmax(tf_output, axis=1)\n",
    "labels = ['Negative','Positive'] #(0:negative, 1:positive)\n",
    "label = tf.argmax(tf_prediction, axis=1)\n",
    "label = label.numpy()\n",
    "print(labels[label[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406faab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
